# Complexity file

```{r}
# libraries

#library(packageCHT) BRANCHEMENT : DEVRA MARCHER UNE FOIS QUE LE PACKAGE SERA COMPLET
library(ggplot2)
```
Petit comme la team pour vous expliquez comment est-ce que j'ai fait : en gros la structure par algo c'est 
1) complexité théorique 
 - regarder le nombre de fois qu'une boucle while est lancé dans le pire des cas ...
2) complexité empirique 
 - lancer plusieurs fois l'algo avec des valeurs de n différentes.  Dans le fichier GS_bucket_complexity_test_function.R il y aun exemple il suffit de modifier une ligne pour avoir une fonction qui prend en argument n et qui renvoie le tmeps que met l'algo à tourner.
 - plot en normal (vs n^2)
 - plot avec une echelle logarithmique
3) R vs C++
 - J'ai un semblant de code qui devrait fonctionner mais à voir si il marche vrm 

## Gale-Shapley

### Complexité théorique

Nous allons calculer théoriquement la complexité de l'algorithme de Gale-Shapley présent dans le ficher GaleShapley.R.

Tout d'abord, notons les complexité au sein des boucles. Notons $n$ le nombre d'homme (= nombre de femme aussi).

```{r}
gale_shapley <- function(men_prefs, women_prefs) {
  free_men <- names(men_prefs)    #O(1)
  engaged <- list()    #O(1)
  next_proposal <- setNames(rep(1, length(free_men)), free_men)    #O(1)

  # Helper function: rank of a man for a woman
  rank <- lapply(women_prefs, function(prefs) setNames(seq_along(prefs), prefs))    #O(n^2) n vector of size n

  while (length(free_men) > 0) {
    man <- free_men[1]    #O(1)
    woman <- men_prefs[[man]][next_proposal[man]]    #O(1)

    # Man proposes
    if (is.null(engaged[[woman]])) {    #O(1)
      engaged[[woman]] <- man    #O(1)
      free_men <- setdiff(free_men, man)    #O(n) worst case
    } else {    #O(1)
      current <- engaged[[woman]]    #O(1)
      if (rank[[woman]][[man]] < rank[[woman]][[current]]) {    #O(1)
        engaged[[woman]] <- man    #O(1)
        free_men <- c(free_men, current)    #O(1)
        free_men <- setdiff(free_men, man)    #O(n) worst case
      } else {    #O(1)
        # Woman rejects this man
      }
    }

    next_proposal[man] <- next_proposal[man] + 1    #O(1)
  }

  matches <- data.frame(    #O(1)
    Man = unlist(engaged),
    Woman = names(engaged),
    stringsAsFactors = FALSE
  )
  return(matches)    #O(1)
}
```

Concernant la boucle while, chaque homme fait sa demande aux femmes dans l'ordre de ses préférences et il ne peut faire sa demande qu'une seule fois.

Nous avons dans le pire des cas $n$ propositions par homme. Vu qu'il y a $n$ homme, cela ferait $n^2$ demandes. Il faut aussi prendre en compte le fait que setdiff() à une complexité linéaire sur la liste prise en argument. Sauf que dans ce cas de figure précis, la liste que setdiff prend en argument (free_men) se retrouverait quasiment vide presque tout le temps. On peut donc négliger sa complexité.

Ainsi :
$$C(\text{Gale-Shapley})=O(n^2)$$
### Complexité empirique

Voyons comment évolue le temps que met l'algorithme à tourner en fonction de $n$.



```{r}
# A SUPPRIMER QUAND LES BRANCHEMENTS SERONT BIEN ORGANISÉS

#' Test the runtime of Gale-Shapley
#'
#' @description Runs the algorithm for random preference lists of size n and returns execution time.
#' @param n Number of men/women.
#' @return Execution time in seconds.
#' @export
test_gs_time <- function(n) {
  men <- paste0("M", 1:n)
  women <- paste0("W", 1:n)

  men_prefs <- lapply(1:n, function(i) sample(women))
  names(men_prefs) <- men

  women_prefs <- lapply(1:n, function(i) sample(men))
  names(women_prefs) <- women

  time <- system.time({
    gale_shapley(men_prefs, women_prefs)
  })
  return(time["elapsed"])
}
```

```{r}
# Choose sizes to test
sizes <- seq(500, 5000, by = 500)

# Measure runtime for each size
times <- sapply(sizes, test_gs_time)

```

```{r}

# Build data frame for plotting
df <- data.frame(
  n = sizes,
  time = times,
  n_squared = (sizes^2) / max(sizes^2) * max(times) # scaled for comparison
)

# Plot measured time and n^2 curve
ggplot(df, aes(x = n)) +
  geom_line(aes(y = time), size = 1.2, color = 'red') +
  geom_point(aes(y = time), size = 2, color = 'red') +
  geom_line(aes(y = n_squared), linetype = "dashed", size = 1, color = 'green') +
  labs(
    title = "Temporal Complexity of Gale–Shapley (Empirical vs n²)",
    x = "n (number of men/women)",
    y = "Execution time (seconds)"
  ) +
  theme_minimal(base_size = 14)
```
On observe bien un temps d'execution quadratique, car si l'on plot avec une échelle logarithmique on observe bien une droite de pente égale à 2.

```{r}
ggplot(df, aes(x = n)) +
  geom_line(aes(y = time), size = 1.2, color = 'red') +
  geom_point(aes(y = time), size = 2, color = 'red') +
  geom_line(aes(y = n_squared), linetype = "dashed", size = 1, color = 'green') +
  labs(
    title = "Gale–Shapley Complexity (Log–Log Scale)",
    x = "log(n)",
    y = "log(time)"
  ) +
  scale_x_log10() +
  scale_y_log10() +
  theme_minimal(base_size = 14)
```

## Gale-Shapley with buckets

### Theoritical Complexity

Partie à faire quand on aura la fonction finale 
```{r}
best_gs_bucket <- function(men_prefs, women_prefs) {
  men_names   <- names(men_prefs)
  women_names <- names(women_prefs)
  n <- length(men_prefs)
  men_index   <- setNames(seq_len(n), men_names)
  women_index <- setNames(seq_len(n), women_names)
  men_pref_num <- vector("list", n)
  for (h in seq_len(n)) {
    men_pref_num[[h]] <- women_index[ men_prefs[[h]] ]
  }
  women_pref_num <- vector("list", n)
  for (f in seq_len(n)) {
    women_pref_num[[f]] <- men_index[ women_prefs[[f]] ]
  }
  women_rank <- vector("list", n)
  for (f in seq_len(n)) {
    pref <- women_pref_num[[f]]
    r <- integer(n)
    for (pos in seq_len(n)) {
      r[ pref[pos] ] <- pos
    }
    women_rank[[f]] <- r
  }
  next_choice <- rep(1L, n)
  matching    <- rep(NA_integer_, n)

  # buckets[[k]] contient des couples (h,f) où k = priorité = next_choice[h]
  buckets <- vector("list", n)

  for (h in seq_len(n)) {
    f <- men_pref_num[[h]][1]
    buckets[[1]] <- append(buckets[[1]], list(c(h, f)))
  }
  while (TRUE) {
    p <- match(TRUE, lengths(buckets) > 0)
    if (is.na(p)) break
    prop <- buckets[[p]][[1]]
    buckets[[p]] <- buckets[[p]][-1]

    h <- prop[1]
    f <- prop[2]
    current <- match(f, matching)

    if (is.na(current)) {

      matching[h] <- f

    } else {
      rc <- women_rank[[f]][current]
      rn <- women_rank[[f]][h]

      if (rn < rc) {
        matching[h]      <- f
        matching[current] <- NA_integer_

        next_choice[current] <- nc <- next_choice[current] + 1L
        if (nc <= n) {
          f2 <- men_pref_num[[current]][nc]
          buckets[[nc]] <- append(buckets[[nc]], list(c(current, f2)))
        }

      } else {
        next_choice[h] <- nh <- next_choice[h] + 1L
        if (nh <= n) {
          f2 <- men_pref_num[[h]][nh]
          buckets[[nh]] <- append(buckets[[nh]], list(c(h, f2)))
        }
      }
    }
  }
  data.frame(
    Man   = men_names,
    Woman = women_names[matching],
    stringsAsFactors = FALSE
  )
}
```

### Empirical complexity

```{r}
# A SUPPRIMER QUAND LES BRANCHEMENT AURONT ETE FAIT

test_gs_bucket_time <- function(n) {
  men <- paste0("M", 1:n)
  women <- paste0("W", 1:n)

  men_prefs <- lapply(1:n, function(i) sample(women))
  names(men_prefs) <- men

  women_prefs <- lapply(1:n, function(i) sample(men))
  names(women_prefs) <- women

  time <- system.time({
    best_gs_bucket(men_prefs, women_prefs)
  })
  return(time["elapsed"])
}
```

```{r}
# Choose sizes to test
sizes <- seq(500, 5000, by = 500)
# Measure runtime for each size
times <- sapply(sizes, test_gs_bucket_time)

```

```{r}
# Build data frame for plotting
df <- data.frame(
  n = sizes,
  time = times,
  n_squared = (sizes^2) / max(sizes^2) * max(times),          # scaled n²
  n_cubed  = (sizes^3) / max(sizes^3) * max(times),
  n_log_n  = (sizes * log(sizes)) / max(sizes * log(sizes)) * max(times)  # scaled n log n
)
```

```{r}
# Plot measured time and n^2, n^3 curve
ggplot(df, aes(x = n)) +
  geom_line(aes(y = time), size = 1.2, color = 'red') +
  geom_point(aes(y = time), size = 2, color = 'red') +
  geom_line(aes(y = n_squared), linetype = "dashed", size = 1, color = 'green') +
  geom_line(aes(y = n_cubed), linetype = "dotdash", size = 1, color = 'blue') +
  labs(
    title = "Time Complexity of Gale–Shapley bucket (Empirical vs n^2 & n^3)",
    x = "n (number of men/women)",
    y = "Execution time (seconds)"
  ) +
  theme_minimal(base_size = 14)
```



```{r}
ggplot(df, aes(x = n)) +
  geom_line(aes(y = time), size = 1.2, color = 'red') +
  geom_point(aes(y = time), size = 2, color = 'red') +
  geom_line(aes(y = n_squared), linetype = "dashed", size = 1, color = 'green') +
  geom_line(aes(y = n_cubed), linetype = "dotdash", size = 1, color = 'blue') +
  labs(
    title = "Gale–Shapley with bucket Complexity (Log–Log Scale)",
    x = "log(n)",
    y = "log(time)"
  ) +
  scale_x_log10() +
  scale_y_log10() +
  theme_minimal(base_size = 14)
```
### R vs C++

```{r}
## A ENLEVER QUAND TOUT SERA MERGE

bench_heap_cpp <- function(n) {
  men  <- paste0("M", 1:n)
  women <- paste0("W", 1:n)

  men_prefs <- lapply(1:n, function(i) sample(women))
  names(men_prefs) <- men

  women_prefs <- lapply(1:n, function(i) sample(men))
  names(women_prefs) <- women

  system.time({
    gale_shapley_heap_cpp(men_prefs, women_prefs)
  })["elapsed"]
}
```

```{r}
times_r   <- sapply(sizes, test_gs_bucket_time)
times_cpp <- sapply(sizes, bench_heap_cpp)

df <- data.frame(
  n = rep(sizes, 2),
  time = c(times_r, times_cpp),
  version = rep(c("R bucket", "C++ Heap"), each = length(sizes))
)
```

```{r}
ggplot(df, aes(x = n, y = time, color = version)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  labs(
    title = "Gale–Shapley Bucket: R vs C++ Runtime Comparison",
    x = "Problem size (n)",
    y = "Elapsed time (seconds)"
  ) +
  theme_minimal(base_size = 14)
```

```{r}
ggplot(df, aes(x = n, y = time, color = version)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  scale_x_log10() +
  scale_y_log10() +
  labs(
    title = "Gale–Shapley Bucket: R vs C++ (Log–Log Scale)",
    x = "log(n)",
    y = "log(time)"
  ) +
  theme_minimal(base_size = 14)
```

## Hopcroft-Karp

### Complexité théorique

Nous allons calculer théoriquement la complexité de l'algorithme de Hopcroft-Karp présent dans le ficher hopcroft_karp.R.

Les complexité sont notés dans le fichier R où nous notons $n$ le nombre de donneurs (= nombre de receveurs aussi) et E le nombre d'edges dans le graphe.

Finalement, voici les temps théoriques pour chaque fonction.

```{r, function complexity, eval=FALSE}
build_compatibility_graph <- function(donors, receivers, ...) {
  # O(n^2)
  ...
}

bfs_hopcroft_karp <- function(graph, donors, matching_donors, matching_receivers) {
  # O(E)
  ...
}
dfs_hopcroft_karp <- function(donor, graph, distance, matching_donor, matching_receiver) {
  # O(E)
  ...
}

hopcroft_karp <- function(graph) {
  # O(E * sqrt(n))
  ...
}

```

Ainsi :
$$C(\text{Hopcroft-Karp})=O(E*\sqrt n)$$
### Complexité empirique

Voyons comment évolue le temps que met l'algorithme à tourner en fonction de $n$.

```{r, test-time}
source("R/hopcroft_karp.R")

#' Test the runtime of Hopcroft-Karp
#'
#' @description Runs the algorithm for random donors and receivers lists of size n and returns execution time.
#' @param n Number of donors/reeivers.
#' @return Execution time in seconds.
#' @export
test_hk_time <- function(n) {
  set.seed(123)
  # Create realistic blood type distribution based on population statistics
  data <- data.frame(
    id = 1:100,
    blood_type = sample(
      c("A+", "A-", "B+", "B-", "AB+", "AB-", "O+", "O-"),
      100, 
      replace = TRUE,
      prob = c(0.34, 0.06, 0.10, 0.02, 0.04, 0.01, 0.38, 0.05)  # US population distribution
    )
  )
  
  # Randomly assign 50 donors and 50 receivers
  donors <- sample(data$id, 50)
  receivers <- setdiff(data$id, donors)
  
  compatibility_table <- create_compatibility_table()
  
  # Measure execution time
  start_time <- Sys.time()
  result <- hopcroft_karp(donors, receivers, data, compatibility_table, can_receive)
  end_time <- Sys.time()
  
  execution_time <- as.numeric(difftime(end_time, start_time, units = "secs"))

  num_edges <- sum(sapply(result$graph, length))
  
  return(list(
    time = execution_time,
    edges = num_edges,
    vertices = 2*n,
    matches = result$matching_size
  ))
}
```

```{r, plot}
library(ggplot2)

# Choose sizes to test
sizes <- seq(100, 5000, by = 500)

# Mesurer pour chaque taille
results <- lapply(sizes, function(n) {
  cat(sprintf("Test avec n = %d...\n", n))
  test_hk_time(n)
})

# Extraire les données
times <- sapply(results, function(r) r$time)
edges <- sapply(results, function(r) r$edges)
vertices <- sapply(results, function(r) r$vertices)
matches <- sapply(results, function(r) r$matches)
df <- data.frame(
  n = sizes,
  time = times,
  edges = edges,
  vertices = vertices,
  matches = matches
)

# Calculer les courbes théoriques
# Pour Hopcroft-Karp : O(E·√V)
# V = 2n (n donneurs + n receveurs)
# E ≈ densité × n² pour un graphe biparti

# Normaliser les courbes pour comparaison visuelle
max_time <- max(df$time)

# Courbe E·√V théorique
df$e_sqrt_v <- (df$edges * sqrt(df$vertices)) / max(df$edges * sqrt(df$vertices)) * max_time

# Courbe n² pour comparaison (incorrecte mais pour référence)
df$n_squared <- (df$n^2) / max(df$n^2) * max_time

# Courbe E (linéaire en E)
df$e_linear <- df$edges / max(df$edges) * max_time

ggplot(df, aes(x = n)) +
  # Temps mesuré (empirique)
  geom_line(aes(y = time, color = "Temps mesuré (empirique)"), 
            size = 1.2) +
  geom_point(aes(y = time, color = "Temps mesuré (empirique)"), 
             size = 2.5) +
  
  # Courbe théorique O(E·√V)
  geom_line(aes(y = e_sqrt_v, color = "O(E·√V) théorique"), 
            linetype = "dashed", size = 1) +
  
  # Courbe O(n²) pour comparaison
  geom_line(aes(y = n_squared, color = "O(n²) pour comparaison"), 
            linetype = "dotted", size = 1, alpha = 0.6) +
  
  scale_color_manual(
    name = "Légende",
    values = c(
      "Temps mesuré (empirique)" = "#E41A1C",
      "O(E·√V) théorique" = "#377EB8",
      "O(n²) pour comparaison" = "#999999"
    )
  ) +
  
  labs(
    title = "Complexité temporelle de Hopcroft-Karp",
    subtitle = "Comparaison : Temps mesuré vs O(E·√V) vs O(n²)",
    x = "n (nombre de donneurs = nombre de receveurs)",
    y = "Temps d'exécution (secondes)",
    caption = sprintf("Nombre d'arêtes moyen : %.0f pour n=%.0f", 
                     mean(df$edges), mean(df$n))
  ) +
  
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 12, color = "gray40")
  )
```
On n'observe pas une comlexité comme théorique O(E·√V) car le graphe n'est pas assez dense. En effet, pour des petites valeurs de n, le nombre d'arêtes est relativement faible comparé à n².

```{r}
# Calculer la pente en échelle log-log
log_n <- log10(df$n)
log_time <- log10(df$time)
log_e_sqrt_v <- log10(df$edges * sqrt(df$vertices))

# Régression linéaire pour estimer la pente empirique
model_time <- lm(log_time ~ log_n)
slope_time <- coef(model_time)[2]

# Régression pour E·√V
model_theory <- lm(log_time ~ log_e_sqrt_v)
slope_theory <- coef(model_theory)[2]

p2 <- ggplot(df, aes(x = n)) +
  # Temps mesuré
  geom_line(aes(y = time, color = "Temps mesuré"), 
            size = 1.2) +
  geom_point(aes(y = time, color = "Temps mesuré"), 
             size = 2.5) +
  
  # Courbe O(E·√V)
  geom_line(aes(y = e_sqrt_v, color = "O(E·√V)"), 
            linetype = "dashed", size = 1) +
  
  # Courbe O(n²)
  geom_line(aes(y = n_squared, color = "O(n²)"), 
            linetype = "dotted", size = 1, alpha = 0.6) +
  
  scale_color_manual(
    name = "Légende",
    values = c(
      "Temps mesuré" = "#E41A1C",
      "O(E·√V)" = "#377EB8",
      "O(n²)" = "#999999"
    )
  ) +
  
  scale_x_log10(
    breaks = c(100, 200, 500, 1000, 2000, 5000),
    labels = c("100", "200", "500", "1k", "2k", "5k")
  ) +
  scale_y_log10() +
  
  labs(
    title = "Complexité de Hopcroft-Karp (Échelle log-log)",
    subtitle = sprintf(
      "Pente empirique : %.2f | Pente théorique O(E·√V) : %.2f | O(n²) : 2.0",
      slope_time, slope_theory
    ),
    x = "log(n) - nombre de donneurs/receveurs",
    y = "log(temps) - secondes",
    caption = "En échelle log-log, une pente de ~1.5 indique O(E·√V)"
  ) +
  
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 11, color = "gray40")
  ) +
  
  # Ajouter des annotations pour les pentes
  annotate("text", x = 500, y = max(df$time) * 0.5, 
           label = sprintf("Pente mesurée ≈ %.2f", slope_time),
           color = "#E41A1C", size = 4, fontface = "bold")

print(p2)
```
